{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 120 Data Science Interview Questions\n",
    "---\n",
    "\n",
    "1. Analyze this dataset and give me a model that can predict this response variable.\n",
    "\n",
    "2. What could be some issues if the distribution of the test data is significantly different than the distribution of the training data?\n",
    "\n",
    "    - Incorrect predictions and classifier.\n",
    "    \n",
    "    **Dataset Shift/Data Fracture**- when training and test distributions are different\n",
    "    \n",
    "    Types of Dataset Shift\n",
    "        * Covariate Shift- shift in the independent variables\n",
    "        * Prior Probability Shift- shift in the target variable\n",
    "        * Concept Shift- shift in the relationship between the independent and target variable\n",
    "    \n",
    "    ![Covariate Shift](http://laoblogger.com/images/covariate-shift-clipart-6.jpg)\n",
    "\n",
    "3. What are some ways I can make my model more robust to outliers?\n",
    "\n",
    "    - Use a model resistant to outliers. Tree-based models are generally not as affected by outliers, while regression-based models are.\n",
    "    - Use a more robust error metric. Minimize the sum of absolute values of errors instead of the sum of squares reduces the influence of outliers.\n",
    "    - Ensemble Methods\n",
    "    \n",
    "    Data Changes\n",
    "        - Remove the outliers\n",
    "        - Transform the data (log, etc...)\n",
    "        - Winsorize- replacing/modifying a specified number of extreme values with a smaller data value (such as assigning the outlier with a lower weight or changing the value so that it is close to other values in the set\n",
    "    \n",
    "4. What are some differences you would expect in a model that minimizes squared error, versus a model that minimizes absolute error? In which cases would each error metric be appropriate?\n",
    "\n",
    "    MAE is more robust to outliers and the MSE is more useful if we are concerned about large errors whose consequences are more severe than smaller errors.\n",
    "    \n",
    "5. What error metric would you use to evaluate how good a binary classifer is? What if the classes are imbalanced? What if there are more than 2 groups?\n",
    "    - Simple accuracy (TP + TN) / (TP + TN + FP + FN)  \n",
    "    \n",
    "    When the dataset is imbalanced, accuracy will be deceiving. Must change performance measure.\n",
    "    - Sensitivity/Recall- measures the ability of a test to detect the condition when the condition is present (TP) / (TP + FN)\n",
    "    - Specificity- measure the ability of a test to not detect the condition when the condition is absent (TN) / (TN + FP)\n",
    "    - Precision- TP / (TP + FP)\n",
    "    - Error Rate- 1 - Precision\n",
    "    - F1- $\\frac{2}{(\\frac{1}{Precision}) + (\\frac{1}{Recall})}$\n",
    "    - ROC\n",
    "    - AUC\n",
    "\n",
    "## Statistics\n",
    "---\n",
    "\n",
    "1. What is the Central Limit Theorem and why is it important?\n",
    "    \n",
    "    If we sample from a population using a sufficiently large sample size (around n=30 is sufficient), the mean of the samples will be normally distributed (regardless of the distribution of the original population). It is important because according to the CLT, even though we might not know the shape of the distribution where our data comes from, the CLT says that we can treat the sampling distribution as if it were normal. More info [here.](https://www.thoughtco.com/importance-of-the-central-limit-theorem-3126556)  \n",
    "    \n",
    "2. What is sampling? How many sampling methods do you know?\n",
    "    \n",
    "    Sampling is the selection of a subset of observations from a population to estimate characteristics of the whole population.\n",
    "    \n",
    "    * Sampling Methods\n",
    "    \n",
    "        * Simple Random Sampling (SRS)- each observation of the population has an equal chance of being selected\n",
    "        * Stratified Sampling- divide the population into homogenous groups (strata), then a probability sample is drawn from each group\n",
    "        * Cluster Sampling- divide the population into naturally occurring groups (clusters), then a SRS of clusters is selected\n",
    "        * Systematic Sampling\n",
    "        * Multistage Sampling\n",
    "        \n",
    "3. What is the difference between Type I and Type II error?\n",
    "\n",
    "    Type I Error- \"False Positive\": detects the condition when the condition is absent  \n",
    "    Type II Error- \"False Negative\": does not detect the condition when the condition is present\n",
    "    \n",
    "4. What is Linear Regression? What do the terms P-value, coefficient, and $R^2$ mean?\n",
    "\n",
    "    - Linear Regression is the supervised learning task for modeling and predicting continuous, numeric variables.\n",
    "    - Can be updated easily with new data using stochastic gradient descent (SGD) and straightforward to understand\n",
    "    \n",
    "    Cons\n",
    "        Performs poorly when there are non-linear relationships\n",
    "    \n",
    "Regularization- technique for penalizing large coefficients in order to avoid overfitting\n",
    "\n",
    "## Random\n",
    "---\n",
    "No Free Lunch Theorem- no one algorithm works best for every problem\n",
    "\n",
    "True Positive (TP): detects the condition when the condition is present\n",
    "True Negative (TN): does not detect the condition when the condition is absent\n",
    "False Positive (FP): detects the condition when the condition is absent\n",
    "False Negative (FN): does not detect the condition when the condition is present\n",
    "\n",
    "\n",
    "\n",
    "## Programming (CTCI)\n",
    "---\n",
    "### Chapter 1- Arrays and Strings\n",
    "\n",
    "- Hash Tables: data structure that maps keys to values for highly efficient lookup\n",
    "    - The hash table has an underlying array and a hash function that maps the key to an integer (which indicates the index in the array)\n",
    "    - To avoid collisions, we store a linked list at each index of the underlying array\n",
    "    - Worst case runtime- O(N)\n",
    "    - Average- O(1)\n",
    "    - We can assume good implementation keeps collisions to a minimum- O(1)\n",
    "    - Could also implemenent with a balanced binary search tree. Guarantees a O(log N) lookup time and uses less space\n",
    "    \n",
    "    \n",
    "- ArrayList & Resizable Arrays\n",
    "    - In some languages, arrays (lists) are automatically resizable. The list grows as you append items.\n",
    "    - O(1) access, O(N) search, insertion, deletion\n",
    "    \n",
    "- StringBuffer/StringBuilder\n",
    "    - Creates an array of all the strings, copying them back to a string only when necessary instead of creating a new copy of the string every time (which is O(x$N^2$))\n",
    "    \n",
    "TODO- implement HashTable, ArrayList, StringBuilder\n",
    "   \n",
    "   \n",
    "### Chapter 2- Linked Lists\n",
    "Data Structure that represents a sequence of nodes\n",
    "\n",
    "Singly Linked List- each node points to the next node in the linked list and stores\n",
    "![Singly LL](https://www.geeksforgeeks.org/wp-content/uploads/gq/2013/03/Linkedlist.png)\n",
    "Doubly Linked List- gives each node pointers to both the next node and the previous node\n",
    "![Doubly LL](https://www.geeksforgeeks.org/wp-content/uploads/gq/2014/03/DLL1.png)\n",
    "\n",
    "Unlike an array, a linked list does not provide constant time access to a particular \"index\" within the list. If you want to find the Kth element, you have to iterate through K elements.\n",
    "\n",
    "Benefit: add/remove items from the beginning of the list in constant time\n",
    "\n",
    "Creating a Singly Linked List\n",
    "\n",
    "`\n",
    "\n",
    "    class Node:\n",
    "        def __init__ (self, data):\n",
    "            self.data = data\n",
    "            self.next = None\n",
    "       \n",
    "    class LinkedList:\n",
    "        def __init__ (self):\n",
    "            self.head = None\n",
    "            self.tail = None  \n",
    "\n",
    "        def add(self, data):\n",
    "            new_node = Node(data)\n",
    "            if self.head == None:\n",
    "                self.head = new_node\n",
    "            elif self.tail != None:\n",
    "                self.tail.next = new_node\n",
    "            self.tail = new_node  \n",
    "\n",
    "        def remove(self, index):\n",
    "            prev = None\n",
    "            node = self.head\n",
    "            i = 0\n",
    "\n",
    "            while (node != None) and (i < index):\n",
    "                prev = node\n",
    "                node = node.next\n",
    "                i += 1\n",
    "            if prev == None:\n",
    "                self.head = node.next\n",
    "            else:\n",
    "                prev.next = node.next\n",
    "`\n",
    "## References \n",
    "---\n",
    "\n",
    "Shan, Carl, et al. 120 Data Science Interview Questions. \n",
    "\n",
    "McDowell, Gayle Laakmann. Cracking the coding interview: 189 programming interview questions and solutions. CareerCup, 2015.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
